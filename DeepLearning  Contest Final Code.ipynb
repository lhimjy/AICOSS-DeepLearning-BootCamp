{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f59404c-fa65-4d16-8833-93812e550e91",
   "metadata": {},
   "source": [
    "# 1. 데이터 전처리 코드\n",
    "\n",
    "데이터 전처리 코드입니다. (좌우 반전, 랜덤 회전 증강)\n",
    "증강한 데이터는 코드와 같은 위치에 저장되도록 경로를 설정해놨습니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec7baee-b659-4902-b81e-259d53a3aa1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation complete.\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 코드입니다.\n",
    "\n",
    "\"\"\"\n",
    "- EDA 인사이트\n",
    "1) EDA를 통해 클래스 별 불균형 확인 (가장 큰건 300장이 넘어가지만, 8장의 이미지를 가지는 클래스도 존재)\n",
    "-> 불균형을 고려한 데이터 증강 필요성\n",
    "\n",
    "추가하고 싶은 것) Train 데이터와 test 데이터의 분포 비교. (이거 해도 되는지 모르겠음..)\n",
    "-> intensity, 주파수 영역 분석해서 분포가 비슷한걸 파악함 -> 이미지 분포를 크게 바꾸지 않는 증강만 고려\n",
    "\n",
    "\n",
    "- 전처리 과정: 데이터 불균형을 고려한 데이터 증강\n",
    "1) 클래스가 새, 자동차, 비행기이므로 좌우 반전 증강 가능.\n",
    "\n",
    "2) 클래스가 새, 자동차, 비행기이므로 현실 세계를 고려하여 45도 이내의 시계/ 반시계 방향 랜덤 회전 \n",
    "-> 이렇게 진행 시 모든 데이터 3배 증가함.\n",
    "\n",
    "3) 이렇게 증강해도 300장이 되지 않는 데이터들에 대하여 45도 이내의 시계/ 반시계 방향 랜덤 회전 또 진행\n",
    "-> 가장 작은 클래스도 300장이 넘어가도록 하여 데이터 불균형 해소\n",
    "\n",
    "\"\"\"\n",
    "import os\n",
    "import random\n",
    "from PIL import Image, ImageOps\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "# 데이터 경로 설정\n",
    "train_dir = \"/test/final_exam/challenge/train\"\n",
    "augmented_dir = \"augmented_train\"\n",
    "os.makedirs(augmented_dir, exist_ok=True)\n",
    "\n",
    "# 증강 함수 정의\n",
    "def augment_images(class_path, save_path, min_count=300):\n",
    "    images = [f for f in os.listdir(class_path) if f.endswith(\".jpg\") or f.endswith(\".png\")]\n",
    "    \n",
    "    # 원본 이미지 불러오기\n",
    "    image_paths = [os.path.join(class_path, img) for img in images]\n",
    "    augmented_images = []\n",
    "\n",
    "    # 좌우 반전\n",
    "    for img_path in image_paths:\n",
    "        with Image.open(img_path) as img:\n",
    "            flipped = ImageOps.mirror(img)\n",
    "            augmented_images.append(flipped)\n",
    "            augmented_images.append(img.copy())\n",
    "\n",
    "    # 랜덤 회전 (시계방향 & 반시계방향 45도 이내)\n",
    "    final_images = []\n",
    "    for img in augmented_images:\n",
    "        for _ in range(2):\n",
    "            angle = random.uniform(-45, 45)\n",
    "            rotated = img.rotate(angle)\n",
    "            final_images.append(rotated)\n",
    "\n",
    "    # 이미지 저장 (최소 100장 확보)\n",
    "    while len(final_images) < min_count:\n",
    "        for img in augmented_images:\n",
    "            angle = random.uniform(-45, 45)\n",
    "            rotated = img.rotate(angle)\n",
    "            final_images.append(rotated)\n",
    "            if len(final_images) >= min_count:\n",
    "                break\n",
    "\n",
    "    # 저장\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    for idx, img in enumerate(final_images):\n",
    "        img.save(os.path.join(save_path, f\"aug_{idx}.jpg\"))\n",
    "\n",
    "# 클래스별 증강 실행\n",
    "for class_name in os.listdir(train_dir):\n",
    "    class_path = os.path.join(train_dir, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        save_path = os.path.join(augmented_dir, class_name)\n",
    "        augment_images(class_path, save_path)\n",
    "\n",
    "print(\"Data augmentation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b117056-6beb-4ab1-9f1d-c20caad85346",
   "metadata": {},
   "source": [
    "# 2. 훈련 + 평가 코드\n",
    "\n",
    "여기서 부터 시드를 저장하고 훈련을 시작합니다.\n",
    "사용한 모델은 EfficientNet_b5입니다. (AdamW + CosineAnnealingLR)\n",
    "\n",
    "batch_size = 36,\n",
    "epochs = 30,\n",
    "num_classes = 300,\n",
    "adamW_lr = 0.001,\n",
    "weight_decay = 1e-4\n",
    "\n",
    "평가는 가장 마지막 모델 훈련 상태 기준으로 진행합니다. (30 에폭 학습 후)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ab42db5-9afb-40eb-87fa-6330c5825cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, torch\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) \n",
    "    random.seed(seed)  \n",
    "    np.random.seed(seed)  \n",
    "    torch.manual_seed(seed)  \n",
    "    torch.cuda.manual_seed(seed)  \n",
    "    torch.cuda.manual_seed_all(seed)  \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# 예시\n",
    "set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7e26876-66b0-4136-8ca9-2ed710921a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# (1) 라이브러리 임포트 및 기본 설정\n",
    "######################################################\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8699211-846e-4a90-9396-6476aa183ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# (2) 하이퍼파라미터 & 경로 설정\n",
    "######################################################\n",
    "batch_size = 36\n",
    "epochs = 30\n",
    "num_classes = 300\n",
    "adamW_lr = 0.001\n",
    "weight_decay = 1e-4\n",
    "\n",
    "# 체크포인트 저장 폴더\n",
    "checkpoint_dir = \"./checkpoint_efficientnet_b5\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)  # 없으면 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cb7c6d5-0f33-4386-b873-ddbe4caed707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples:   89178\n",
      "Validation samples: 4694\n",
      "Test samples:       4178\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# (3) 데이터 변환 & 데이터셋/로더 정의\n",
    "######################################################\n",
    "\n",
    "size = (456, 456)\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(size),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "origin_train_dataset = torchvision.datasets.ImageFolder(root='./augmented_train', transform=transform)\n",
    "test_dataset = torchvision.datasets.ImageFolder(root='/test/final_exam/challenge/test', transform=transform)\n",
    "\n",
    "# train, valid 층화추출\n",
    "# Dataset 전체의 클래스 레이블 가져오기\n",
    "targets = [origin_train_dataset.targets[i] for i in range(len(origin_train_dataset))]\n",
    "\n",
    "# train, valid 셋 클래스 비율을 맞추기 위한 층화추출\n",
    "# 층화추출을 위한 StratifiedShuffleSplit 설정\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.05, random_state=42)  # train: 95%, valid: 5%\n",
    "\n",
    "# train_index와 valid_index 생성\n",
    "for train_index, valid_index in split.split(np.zeros(len(targets)), targets):\n",
    "    train_indices = train_index\n",
    "    valid_indices = valid_index\n",
    "\n",
    "# Subset을 사용하여 Train과 Valid Dataset 생성\n",
    "train_dataset = Subset(origin_train_dataset, train_indices)\n",
    "validation_dataset = Subset(origin_train_dataset, valid_indices)\n",
    "\n",
    "# DataLoader 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Training samples:   {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(validation_dataset)}\")\n",
    "print(f\"Test samples:       {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e97783b6-872c-4208-b096-d3f4714f3098",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# (4) 모델 정의 (EfficientNet-B5, scratch) & (선택)체크포인트 로드\n",
    "######################################################\n",
    "# 처음부터(scratch) → weights=None\n",
    "effnet_b5 = models.efficientnet_b5(weights=None)\n",
    "\n",
    "# 분류기 부분 수정 → 출력 차원 = 300개\n",
    "in_features = effnet_b5.classifier[1].in_features  # 일반적으로 1536\n",
    "effnet_b5.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "model = effnet_b5.to(device)\n",
    "\n",
    "# [원하는 체크포인트 로드 시 주석 해제 예시]\n",
    "# ckpt_path = os.path.join(checkpoint_dir, \"checkpoint_epoch_37.pth\")\n",
    "# model.load_state_dict(torch.load(ckpt_path))\n",
    "# print(f\"Loaded checkpoint: {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f764ab4f-0afb-46aa-9271-6f90bb2c77d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# (5) 옵티마이저, 스케줄러, 손실함수 정의\n",
    "######################################################\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "adamw_optimizer = torch.optim.AdamW(model.parameters(), lr=adamW_lr, weight_decay=weight_decay)\n",
    "adamw_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(adamw_optimizer, T_max=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72a57cd9-3cfb-40be-abd5-160b55ef7977",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# (6) 학습 함수, 검증 함수, 테스트 함수\n",
    "######################################################\n",
    "def train_model(num_epochs=epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        optimizer, scheduler = adamw_optimizer, adamw_scheduler\n",
    "        \n",
    "        model.train()\n",
    "        running_loss  = 0.0\n",
    "        total_batches = len(train_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if (batch_idx + 1) % 10 == 0 or (batch_idx + 1) == total_batches:\n",
    "                print(f\"  [Batch {batch_idx+1}/{total_batches}] Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # Validation Loss\n",
    "        val_loss = validate_model()\n",
    "\n",
    "        # 매 Epoch마다 체크포인트 저장\n",
    "        ckpt_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch+1}.pth\")\n",
    "        torch.save(model.state_dict(), ckpt_path)\n",
    "        print(f\"Checkpoint saved: {ckpt_path}\")\n",
    "\n",
    "        # 스케줄러 step\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"==> Epoch [{epoch+1}/{num_epochs}] \"\n",
    "              f\"Train Loss: {running_loss/total_batches:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f} | \"\n",
    "              f\"LR: {scheduler.get_last_lr()[0]:.6f}\\n\")\n",
    "\n",
    "def validate_model():\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in validation_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "    return val_loss / len(validation_loader)\n",
    "\n",
    "def test_model(model, data_loader):\n",
    "    model.eval()\n",
    "    correct    = 0\n",
    "    total      = 0\n",
    "    all_preds  = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            total   += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # F1, 혼동행렬 등을 위해 저장\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = 100.0 * correct / total\n",
    "    print(f\"Test Accuracy: {acc:.2f}%\")\n",
    "    return all_labels, all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ca8992",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# (7) 학습\n",
    "######################################################\n",
    "train_model(epochs)\n",
    "print(\"----- Training Finished -----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e76b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# (8) 평가(Eval) & CSV 제출\n",
    "######################################################\n",
    "# (선택) 원하는 체크포인트 로드 - 주석 해제 시 사용\n",
    "# custom_ckpt = os.path.join(checkpoint_dir, \"checkpoint_epoch_14.pth\")\n",
    "# model.load_state_dict(torch.load(custom_ckpt))\n",
    "# print(f\"Loaded checkpoint: {custom_ckpt}\")\n",
    "\n",
    "print(\"[Step 8] Evaluating current model & Saving CSV...\")\n",
    "all_labels_main, all_preds_main = test_model(model, test_loader)\n",
    "\n",
    "submission_main = pd.read_csv('./sample_submission.csv')\n",
    "submission_main['Label'] = all_preds_main\n",
    "submission_main.to_csv('./Competition.csv', index=False)\n",
    "print(\"Competition file saved as 'Competition.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06332a76-a56d-4078-9809-8e52f8146972",
   "metadata": {},
   "source": [
    "# 3. 추가 학습 + 평가\n",
    "\n",
    "위에서 30 에폭 학습 후, 아직 val loss가 더 아래로 수렴할 가능성이 있다고 판단하여 추가 학습을 진행했습니다.\n",
    "\n",
    "damW_lr = 5e-5 (추가 학습에 사용할 LR),\n",
    "weight_decay = 1e-4\n",
    "추가 에폭 수 = 20 (전부 다 사용하지 않음)\n",
    "\n",
    "시간 제약을 고려하여 val loss가 어느정도 수렴하는 지점인 37에폭 (기존 30 + 추가 7에폭)에서 학습을 종료 했습니다.\n",
    "\n",
    "평가는 모든 가중치에 대하여 할 수 있도록 구현했습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a17d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# (8) 추가 학습: 원하는 체크포인트 로드 후 이어서 학습\n",
    "######################################################\n",
    "\n",
    "# 체크포인트 디렉토리 설정\n",
    "checkpoint_dir = \"checkpoint_efficientnet_b5\"\n",
    "new_checkpoint_dir = \"checkpoint_efficientnet_b5_fine\"\n",
    "os.makedirs(new_checkpoint_dir, exist_ok=True)  # 새로운 디렉토리 생성\n",
    "\n",
    "# 모델 및 옵티마이저 초기화\n",
    "adamW_lr = 5e-5  # 추가 학습에 사용할 학습률\n",
    "weight_decay = 1e-4\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "adamw_optimizer = torch.optim.AdamW(model.parameters(), lr=adamW_lr, weight_decay=weight_decay)\n",
    "adamw_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(adamw_optimizer, T_max=7)  # 20 에폭 기준\n",
    "\n",
    "# 원하는 체크포인트 로드\n",
    "ckpt_path = os.path.join(checkpoint_dir, \"checkpoint_epoch_30.pth\")  # 체크포인트 경로\n",
    "if os.path.exists(ckpt_path):\n",
    "    model.load_state_dict(torch.load(ckpt_path))\n",
    "    print(f\"Loaded checkpoint from: {ckpt_path}\")\n",
    "else:\n",
    "    print(f\"Checkpoint not found: {ckpt_path}\")\n",
    "\n",
    "# 추가 학습 함수\n",
    "def fine_tune_model(start_epoch=31, num_epochs=20):\n",
    "    for epoch in range(start_epoch, start_epoch + num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        total_batches = len(train_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{start_epoch + num_epochs - 1}\")\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            adamw_optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            adamw_optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if (batch_idx + 1) % 10 == 0 or (batch_idx + 1) == total_batches:\n",
    "                print(f\"  [Batch {batch_idx+1}/{total_batches}] Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # Validation Loss\n",
    "        val_loss = validate_model()\n",
    "\n",
    "        # 체크포인트 저장\n",
    "        ckpt_path = os.path.join(new_checkpoint_dir, f\"checkpoint_epoch_{epoch}.pth\")\n",
    "        torch.save(model.state_dict(), ckpt_path)\n",
    "        print(f\"Checkpoint saved: {ckpt_path}\")\n",
    "\n",
    "        # 스케줄러 step\n",
    "        adamw_scheduler.step()\n",
    "\n",
    "        print(f\"==> Epoch [{epoch}/{start_epoch + num_epochs - 1}] \"\n",
    "              f\"Train Loss: {running_loss/total_batches:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f} | \"\n",
    "              f\"LR: {adamw_scheduler.get_last_lr()[0]:.6f}\\n\")\n",
    "\n",
    "# 추가 학습 실행\n",
    "fine_tune_model(start_epoch=31, num_epochs=20)\n",
    "print(\"----- Fine-tuning Finished -----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91db2065-d3f5-41c2-aade-0cbfe22e7874",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## 원하는 가중치로 eval 코드 : 37 에폭 (이건 결과 보고) ###############\n",
    "# 저장된 가중치 불러오기\n",
    "ckpt_path = \"./checkpoint_efficientnet_b5_fine/checkpoint_epoch_37.pth\"  # 학습된 가중치 경로\n",
    "model.load_state_dict(torch.load(ckpt_path))\n",
    "print(f\"Loaded checkpoint: {ckpt_path}\")\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "print(\"[Step 8] Evaluating current model & Saving CSV...\")\n",
    "all_labels_main, all_preds_main = test_model(model, test_loader)\n",
    "\n",
    "submission_main = pd.read_csv('./sample_submission.csv')  # 기존 제공된 샘플 파일 로드\n",
    "submission_main['Label'] = all_preds_main  # 예측 결과 저장\n",
    "submission_main.to_csv('./Competition_epoch37_b5.csv', index=False)  # CSV 파일로 저장\n",
    "print(\"Competition file saved as 'Competition_epochMain37_b5.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "1_pytorch_2.5.1",
   "language": "python",
   "name": "1_pytorch_2.5.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
